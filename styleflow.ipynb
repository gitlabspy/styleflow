{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "styleflow.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZ1GYAhNqhsv"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "from tensorflow_probability.python import math as tfp_math\n",
        "from tensorflow_probability.python.bijectors import bijector\n",
        "from tensorflow_probability.python.internal import cache_util\n",
        "from tensorflow_probability.python.internal import prefer_static\n",
        "import numpy as np \n",
        "\n",
        "tfd = tfp.distributions\n",
        "tfb = tfp.bijectors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpyOA1P9vDQC"
      },
      "source": [
        "# Copied and modified from tfb.FFJORD into a conditional one (taking extra inputs).\n",
        "def trace_jacobian_hutchinson(\n",
        "    ode_fn,\n",
        "    state_shape,\n",
        "    dtype,\n",
        "    condition,\n",
        "    sample_fn=tf.random.normal,\n",
        "    num_samples=1,\n",
        "    seed=None):\n",
        "  random_samples = sample_fn(\n",
        "      prefer_static.concat([[num_samples], state_shape], axis=0),\n",
        "      dtype=dtype, seed=seed)\n",
        "\n",
        "  def augmented_ode_fn(time, state_log_det_jac):\n",
        "    state, _ = state_log_det_jac\n",
        "    with tf.GradientTape(persistent=True,\n",
        "                         watch_accessed_variables=False) as tape:\n",
        "      tape.watch(state) # I'm not sure should condition be watched/required grad or not... \n",
        "      state_time_derivative = ode_fn(time, state, condition) # might be better putting condition into state.\n",
        "\n",
        "    def estimate_trace(random_sample):\n",
        "      jvp = tape.gradient(state_time_derivative, state, random_sample)\n",
        "      return random_sample * jvp\n",
        "\n",
        "    results = tf.map_fn(estimate_trace, random_samples)\n",
        "    trace_estimates = tf.reduce_mean(results, axis=0)\n",
        "    return state_time_derivative, trace_estimates\n",
        "\n",
        "  return augmented_ode_fn\n",
        "\n",
        "class FFJORD(bijector.Bijector):\n",
        "  def __init__(\n",
        "      self,\n",
        "      state_time_derivative_fn,\n",
        "      ode_solve_fn=None,\n",
        "      trace_augmentation_fn=trace_jacobian_hutchinson,\n",
        "      initial_time=0.,\n",
        "      final_time=1.,\n",
        "      validate_args=False,\n",
        "      dtype=tf.float32,\n",
        "      name='ffjord'):\n",
        "    parameters = dict(locals())\n",
        "    with tf.name_scope(name) as name:\n",
        "      self._initial_time = initial_time\n",
        "      self._final_time = final_time\n",
        "      self._ode_solve_fn = ode_solve_fn\n",
        "      if self._ode_solve_fn is None:\n",
        "        self._ode_solver = tfp_math.ode.DormandPrince()\n",
        "        self._ode_solve_fn = self._ode_solver.solve\n",
        "      self._trace_augmentation_fn = trace_augmentation_fn\n",
        "      self._state_time_derivative_fn = state_time_derivative_fn\n",
        "\n",
        "      def inverse_state_time_derivative(time, state, condition):\n",
        "        return -state_time_derivative_fn(self._final_time - time, state, condition)\n",
        "\n",
        "      self._inv_state_time_derivative_fn = inverse_state_time_derivative\n",
        "      super(FFJORD, self).__init__(\n",
        "          forward_min_event_ndims=0,\n",
        "          dtype=dtype,\n",
        "          validate_args=validate_args,\n",
        "          parameters=parameters,\n",
        "          name=name)\n",
        "\n",
        "  def _solve_ode(self, ode_fn, state):\n",
        "    integration_result = self._ode_solve_fn(\n",
        "        ode_fn=ode_fn,\n",
        "        initial_time=self._initial_time,\n",
        "        initial_state=state,\n",
        "        solution_times=[self._final_time])\n",
        "    final_state = tf.nest.map_structure(\n",
        "        lambda x: x[-1], integration_result.states)\n",
        "    return final_state\n",
        "\n",
        "  def _augmented_forward(self, x, cond):\n",
        "    \"\"\"Computes forward and forward_log_det_jacobian transformations.\"\"\"\n",
        "    augmented_ode_fn = self._trace_augmentation_fn(\n",
        "        self._state_time_derivative_fn, x.shape, x.dtype, cond)\n",
        "    augmented_x = (x, tf.zeros(shape=x.shape, dtype=x.dtype))\n",
        "    y, fldj = self._solve_ode(augmented_ode_fn, augmented_x)\n",
        "    return y, {'ildj': -fldj, 'fldj': fldj}\n",
        "\n",
        "  def _augmented_inverse(self, y, cond):\n",
        "    \"\"\"Computes inverse and inverse_log_det_jacobian transformations.\"\"\"\n",
        "    augmented_inv_ode_fn = self._trace_augmentation_fn(\n",
        "        self._inv_state_time_derivative_fn, y.shape, y.dtype, cond)\n",
        "    augmented_y = (y, tf.zeros(shape=y.shape, dtype=y.dtype))\n",
        "    x, ildj = self._solve_ode(augmented_inv_ode_fn, augmented_y)\n",
        "    return x, {'ildj': ildj, 'fldj': -ildj}\n",
        "\n",
        "  def _forward(self, x, cond):\n",
        "    y, _ = self._augmented_forward(x, cond)\n",
        "    return y\n",
        "\n",
        "  def _inverse(self, y, cond):\n",
        "    x, _ = self._augmented_inverse(y, cond)\n",
        "    return x\n",
        "\n",
        "  def _forward_log_det_jacobian(self, x, cond):\n",
        "    return self._augmented_forward(x, cond)[1]['fldj']\n",
        "\n",
        "  def _inverse_log_det_jacobian(self, y, cond):\n",
        "    return self._augmented_inverse(y, cond)[1]['ildj']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxB1CUkBtpcq"
      },
      "source": [
        "# ODE function\n",
        "\n",
        "class ConcatSquash(tf.keras.Model):\n",
        "  def __init__(self, nhidden=512):\n",
        "    super(ConcatSquash, self).__init__()\n",
        "    self.dense = tf.keras.layers.Dense(nhidden)\n",
        "    self._hyper_bias = tf.keras.layers.Dense(nhidden, use_bias=False)\n",
        "    self._hyper_gate = tf.keras.layers.Dense(nhidden, activation='sigmoid')\n",
        "\n",
        "  def call(self, t, x, cond):\n",
        "    return self.dense(x) * self._hyper_gate(cond) + self._hyper_bias(cond)\n",
        "\n",
        "\n",
        "class ODEFnc(tf.keras.Model):\n",
        "  def __init__(self, nhidden=512, stack=4):\n",
        "    super(ODEFnc, self).__init__()\n",
        "    self.concatsquash = [ConcatSquash(nhidden=nhidden) for i in range(stack)]\n",
        "  def call(self, t, x, cond):\n",
        "    t = tf.broadcast_to(t, tf.shape(cond))\n",
        "    cond = tf.concat([t, cond], axis=-1)\n",
        "    for lyr in self.concatsquash:\n",
        "      x = lyr(t, x, cond)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLUaDEC3qryq"
      },
      "source": [
        "# Set up model, bijectors, distribution(styleflow) and ode solver.\n",
        "mlp_model = ODEFnc()\n",
        "solver = tfp.math.ode.DormandPrince(atol=1e-5)\n",
        "ode_solve_fn = solver.solve\n",
        "ffjord = FFJORD(\n",
        "        state_time_derivative_fn=mlp_model,ode_solve_fn=ode_solve_fn,\n",
        "        trace_augmentation_fn=trace_jacobian_hutchinson)\n",
        "moving_batchnorm = tfb.Chain([tfb.BatchNormalization(), ffjord, tfb.BatchNormalization()])\n",
        "base_loc = np.zeros((512,)).astype(np.float32)\n",
        "base_sigma = np.ones((512,)).astype(np.float32)\n",
        "base_distribution = tfd.MultivariateNormalDiag(base_loc, base_sigma)\n",
        "styleflow = tfd.TransformedDistribution(\n",
        "    distribution=base_distribution, bijector=moving_batchnorm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tddqZG9vqr2x"
      },
      "source": [
        "# here, an example show you how to pass condition to the model, yeah.\n",
        "awesome_tensorflow_probability_extra_input_passing_kwargs_way_params_dict = {'bijector_kwargs': {'ffjord':{'cond': tf.random.normal((1, 2))}}}\n",
        "styleflow.log_prob(styleflow.sample(1, **awesome_tensorflow_probability_extra_input_passing_kwargs_way_params_dict), **awesome_tensorflow_probability_extra_input_passing_kwargs_way_params_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8NHmuIq4lKS"
      },
      "source": [
        "**Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlYK-rCj5YC8"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "# I don't have any labels currently but you can simply use stylegan to generate some images(10k-20k according to the author),\n",
        "# and save those images corresponding w with shape (512,). Meanwhile, you use those generated images to pass in some trained\n",
        "# classifier like age regression model, gender classification model, or any kind of classification model to get each image's \n",
        "# corresponding labels.\n",
        "# Let say all w and corresponding labels are loaded here...\n",
        "\n",
        "def augment(w, cond):\n",
        "    ## some data pre-process\n",
        "    ## some labels might need to be processed to one-hot like. depends on what labels and how you want it to be looked like.\n",
        "    ## one thing you need to remember is the label shape should be (batch_size, label_size) since the odefunc given above \n",
        "    ## adapted in this way. \n",
        "    return w, cond\n",
        "\n",
        "train_data = tf.data.Dataset.from_tensor_slices((w, cond)).map(augment).batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJItowhqwhAE"
      },
      "source": [
        "optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "\n",
        "@tf.function()\n",
        "def train_step(x):\n",
        "    with tf.GradientTape() as tape:\n",
        "        log_prob_loss = -styleflow.log_prob(x[0], **{'bijector_kwargs':{'ffjord':{'cond':x[1]}}})\n",
        "    variables = tape.watched_variables()\n",
        "    grads = tape.gradient(log_prob_loss, variables)\n",
        "    optimizer.apply_gradients(zip(grads, variables))\n",
        "    return tf.reduce_mean(log_prob_loss)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iz8CPGuwhED"
      },
      "source": [
        "ckpt = tf.train.Checkpoint(model=styleflow)\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, './styleflow', max_to_keep=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a9-MO7n4Eyz"
      },
      "source": [
        "for epoch in range(10):\n",
        "    for i, x in enumerate(train_data):\n",
        "        loss = train_step(x)\n",
        "        print('epoch: ', epoch, 'iter: ', i, ' loss: ', loss.numpy(), '**', end='\\r')\n",
        "    ckpt_manager.save()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HHU_nO84E1J"
      },
      "source": [
        "### trained!\n",
        "### random sample with fixed condition. (sampling w with given labels, then you use this w to generate image with stylegan.)\n",
        "w = styleflow.sample(1, **{'bijector_kwargs': {'ffjord':{'cond': labels}}})\n",
        "\n",
        "### conditional editing. changing given person's attributes.\n",
        "### first encode the w you want to change\n",
        "code = styleflow.bijector.inverse(given_w, **{'ffjord':{'cond': w_corresponding_labels}})  \n",
        "\n",
        "### second decode it with new labels\n",
        "w_prime = styleflow.bijector.inverse(given_w, **{'ffjord':{'cond': new_labels}}) \n",
        "\n",
        "### finally use w_prime to generate image in stylegan with style mixing."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Io9Omsd4E5J"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGfcUH354E7p"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvOu3cb04E-8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOtFLtbtwhIQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9D1Lj2_kwhLp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}